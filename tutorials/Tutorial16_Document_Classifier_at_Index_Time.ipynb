{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extending your Metadata using DocumentClassifiers at Index Time\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial8_Preprocessing.ipynb)\n",
    "\n",
    "DocumentClassifier adds the classification result (label and score) to Document's meta property. \n",
    "Hence, we can use it to classify documents at index time. The result can be accessed at query time: for example by applying a filter for \"classification.label\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This tutorial will show you how to integrate a classification model into your preprocessing steps and how you can filter for this additional metadata at query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's start by installing Haystack\n",
    "\n",
    "# Install the latest release of Haystack in your own environment\n",
    "#! pip install farm-haystack\n",
    "\n",
    "# Install the latest master of Haystack\n",
    "!pip install grpcio-tools==1.34.1\n",
    "!pip install git+https://github.com/deepset-ai/haystack.git\n",
    "!wget --no-check-certificate https://dl.xpdfreader.com/xpdf-tools-linux-4.03.tar.gz\n",
    "!tar -xvf xpdf-tools-linux-4.03.tar.gz && sudo cp xpdf-tools-linux-4.03/bin64/pdftotext /usr/local/bin\n",
    "\n",
    "# If you run this notebook on Google Colab, you might need to\n",
    "# restart the runtime after installing haystack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here are the imports we need\n",
    "from haystack.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.nodes import PreProcessor, TransformersDocumentClassifier, FARMReader, ElasticsearchRetriever\n",
    "from haystack.schema import Document\n",
    "from haystack.utils import convert_files_to_dicts, fetch_archive_from_http, print_answers, launch_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fetches some sample files to work with\n",
    "\n",
    "doc_dir = \"data/preprocessing_tutorial\"\n",
    "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/preprocessing_tutorial.zip\"\n",
    "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## read and preprocess documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pdftotext version 0.86.1\n",
      "Copyright 2005-2020 The Poppler Developers - http://poppler.freedesktop.org\n",
      "Copyright 1996-2011 Glyph & Cog, LLC\n",
      "100%|██████████| 3/3 [00:00<00:00, 324.71docs/s]\n"
     ]
    }
   ],
   "source": [
    "# note that you can also use the document classifier before applying the PreProcessor, e.g. before splitting your documents\n",
    "\n",
    "all_docs = convert_files_to_dicts(dir_path=\"data/preprocessing_tutorial\")\n",
    "preprocessor_sliding_window = PreProcessor(\n",
    "    split_overlap=3,\n",
    "    split_length=10,\n",
    "    split_respect_sentence_boundary=False\n",
    ")\n",
    "docs_sliding_window = preprocessor_sliding_window.process(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DocumentClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can enrich the document metadata at index time using any transformers document classifier model.\n",
    "Here we use an emotion model that distinguishes between 'sadness', 'joy', 'love', 'anger', 'fear' and 'surprise'.\n",
    "These classes can later on be accessed at query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_classifier_model = 'bhadresh-savani/distilbert-base-uncased-emotion'\n",
    "doc_classifier = TransformersDocumentClassifier(model_name_or_path=doc_classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Document using a fieldmap for custom content fields the classification should run on\n",
    "field_map = {}\n",
    "docs_to_classify = [Document.from_dict(d, field_map=field_map) for d in docs_sliding_window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify using gpu, batch_size makes sure we do not run out of memory\n",
    "classified_docs = doc_classifier.predict(docs_to_classify, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to dicts if you want, note that DocumentStore.write_documents() can handle Documents too\n",
    "# classified_docs = [doc.to_dict(field_map=field_map) for doc in classified_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Heavy metal\\n\\nHeavy metal (or simply metal) is a genre of', 'content_type': 'text', 'score': None, 'meta': {'name': 'heavy_metal.docx', '_split_id': 0, 'classification': {'label': 'anger', 'score': 0.5151640772819519}}, 'embedding': None, 'id': '9903d23737f3d05a9d9ee170703dc245'}\n"
     ]
    }
   ],
   "source": [
    "# let's see how it looks: there should be a classification result in the meta entry containing label and score.\n",
    "print(classified_docs[0].to_dict(field_map=field_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Colab / No Docker environments: Start Elasticsearch from source\n",
    "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "! chown -R daemon:daemon elasticsearch-7.9.2\n",
    "\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
    "                   stdout=PIPE, stderr=STDOUT,\n",
    "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
    "                  )\n",
    "# wait until ES has started\n",
    "! sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's write the docs to our DB.\n",
    "document_store.write_documents(classified_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 9903d23737f3d05a9d9ee170703dc245 has label anger\n"
     ]
    }
   ],
   "source": [
    "# check if indexed docs contain classification results\n",
    "test_doc = document_store.get_all_documents()[0]\n",
    "print(f'document {test_doc.id} has label {test_doc.meta[\"classification\"][\"label\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QA-Pipeline\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]/home/tstad/git/haystack/haystack/modeling/model/prediction_head.py:455: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.09 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.24 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.40 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.55 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.98 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.99 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "## Voilà! Ask a question while filtering for \"joy\"-only documents\n",
    "prediction = pipe.run(\n",
    "    query=\"How is heavy metal?\", params={\"Retriever\": {\"top_k\": 10, \"filters\": {\"classification.label\": [\"joy\"]}}, \"Reader\": {\"top_k\": 5}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'answers': [   Answer(answer='thick, massive sound', type='extractive', score=0.6946582794189453, context=',[6] heavy metal bands developed a thick, massive sound, characterized', offsets_in_document=[Span(start=35, end=55)], offsets_in_context=[Span(start=35, end=55)], document_id='b69a8816c2c8d782dceb412b80a4bf6e', meta={'_split_id': 5, 'classification': {'label': 'joy', 'score': 0.9432986974716187}, 'name': 'heavy_metal.docx'}),\n",
      "                   Answer(answer='modified heavy metal into more accessible forms', type='extractive', score=0.2581551596522331, context='Several American bands modified heavy metal into more accessible forms', offsets_in_document=[Span(start=23, end=70)], offsets_in_context=[Span(start=23, end=70)], document_id='5a9cefc4732e4b2f97529a79231345ec', meta={'_split_id': 13, 'classification': {'label': 'joy', 'score': 0.9782285094261169}, 'name': 'heavy_metal.docx'}),\n",
      "                   Answer(answer='fans', type='extractive', score=0.08210562914609909, context='decade, heavy metal fans became known as \"\" or \"\".\\nDuring', offsets_in_document=[Span(start=20, end=24)], offsets_in_context=[Span(start=20, end=24)], document_id='ac5cc61f3e646d87d6549a7bb80b8b4a', meta={'_split_id': 26, 'classification': {'label': 'joy', 'score': 0.49669304490089417}, 'name': 'heavy_metal.docx'}),\n",
      "                   Answer(answer='GPT is trained', type='extractive', score=0.022879733704030514, context='other differences\\nbetween how BERT and GPT were trained:\\nGPT is trained', offsets_in_document=[Span(start=56, end=70)], offsets_in_context=[Span(start=56, end=70)], document_id='d7275b6ce4becbb9a36598371acd2d85', meta={'_split_id': 1028, 'classification': {'label': 'joy', 'score': 0.4063064754009247}, 'name': 'bert.pdf'}),\n",
      "                   Answer(answer='similar', type='extractive', score=0.01282330323010683, context='annotated with a score from 1\\nto 5 denoting how similar', offsets_in_document=[Span(start=48, end=55)], offsets_in_context=[Span(start=48, end=55)], document_id='a20379dd599d8ab52c287a2412c9c1f3', meta={'_split_id': 1092, 'classification': {'label': 'joy', 'score': 0.7392711043357849}, 'name': 'bert.pdf'})],\n",
      "    'documents': [   {'content': 'decade, heavy metal fans became known as \"\" or \"\".\\nDuring', 'content_type': 'text', 'score': 0.8256961596331841, 'meta': {'_split_id': 26, 'classification': {'label': 'joy', 'score': 0.49669304490089417}, 'name': 'heavy_metal.docx'}, 'embedding': None, 'id': 'ac5cc61f3e646d87d6549a7bb80b8b4a'},\n",
      "                     {'content': ',[6] heavy metal bands developed a thick, massive sound, characterized', 'content_type': 'text', 'score': 0.8172186978337235, 'meta': {'_split_id': 5, 'classification': {'label': 'joy', 'score': 0.9432986974716187}, 'name': 'heavy_metal.docx'}, 'embedding': None, 'id': 'b69a8816c2c8d782dceb412b80a4bf6e'},\n",
      "                     {'content': 'Several American bands modified heavy metal into more accessible forms', 'content_type': 'text', 'score': 0.8172186978337235, 'meta': {'_split_id': 13, 'classification': {'label': 'joy', 'score': 0.9782285094261169}, 'name': 'heavy_metal.docx'}, 'embedding': None, 'id': '5a9cefc4732e4b2f97529a79231345ec'},\n",
      "                     {'content': 'similar vein. By the end of the decade, heavy metal', 'content_type': 'text', 'score': 0.8172186978337235, 'meta': {'_split_id': 25, 'classification': {'label': 'joy', 'score': 0.45093369483947754}, 'name': 'heavy_metal.docx'}, 'embedding': None, 'id': 'f99c648859137f46860d2e14a7524012'},\n",
      "                     {'content': 'studies is concerned with how students of classical texts have', 'content_type': 'text', 'score': 0.7329468403569569, 'meta': {'_split_id': 318, 'classification': {'label': 'joy', 'score': 0.964034914970398}, 'name': 'classics.txt'}, 'embedding': None, 'id': '6f9f737c8b5ded61de3709550ab35c8d'},\n",
      "                     {'content': 'other differences\\nbetween how BERT and GPT were trained:\\nGPT is trained', 'content_type': 'text', 'score': 0.7190529764549188, 'meta': {'_split_id': 1028, 'classification': {'label': 'joy', 'score': 0.4063064754009247}, 'name': 'bert.pdf'}, 'embedding': None, 'id': 'd7275b6ce4becbb9a36598371acd2d85'},\n",
      "                     {'content': 'Clune, Yoshua Bengio, and Hod\\nLipson. 2014. How transferable are features', 'content_type': 'text', 'score': 0.6730417056637098, 'meta': {'_split_id': 881, 'classification': {'label': 'joy', 'score': 0.9823251366615295}, 'name': 'bert.pdf'}, 'embedding': None, 'id': '91e11674d8084bf5775a6bb239491b21'},\n",
      "                     {'content': 'annotated with a score from 1\\nto 5 denoting how similar', 'content_type': 'text', 'score': 0.6730417056637098, 'meta': {'_split_id': 1092, 'classification': {'label': 'joy', 'score': 0.7392711043357849}, 'name': 'bert.pdf'}, 'embedding': None, 'id': 'a20379dd599d8ab52c287a2412c9c1f3'},\n",
      "                     {'content': 'denoting how similar the two sentences are in\\nterms of semantic', 'content_type': 'text', 'score': 0.6730417056637098, 'meta': {'_split_id': 1093, 'classification': {'label': 'joy', 'score': 0.8728417754173279}, 'name': 'bert.pdf'}, 'embedding': None, 'id': '81b7d36f4e974158f2966a08e61e60dd'},\n",
      "                     {'content': 'work survive is Menander, whose style is known as New', 'content_type': 'text', 'score': 0.5870210969454024, 'meta': {'_split_id': 418, 'classification': {'label': 'joy', 'score': 0.9808614253997803}, 'name': 'classics.txt'}, 'embedding': None, 'id': 'aa49c5dd99b6fc78faa055bff878f3e0'}],\n",
      "    'no_ans_gap': 5.921252250671387,\n",
      "    'node_id': 'Reader',\n",
      "    'params': {   'Reader': {'top_k': 5},\n",
      "                  'Retriever': {   'filters': {'classification.label': ['joy']},\n",
      "                                   'top_k': 10}},\n",
      "    'query': 'How is heavy metal?',\n",
      "    'root_node': 'Query'}\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## About us\n",
    "\n",
    "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
    "\n",
    "We bring NLP to the industry via open source!  \n",
    "Our focus: Industry specific language models & large scale QA systems.  \n",
    "  \n",
    "Some of our other work: \n",
    "- [German BERT](https://deepset.ai/german-bert)\n",
    "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
    "- [FARM](https://github.com/deepset-ai/FARM)\n",
    "\n",
    "Get in touch:\n",
    "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Slack](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
    "\n",
    "By the way: [we're hiring!](https://www.deepset.ai/jobs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
